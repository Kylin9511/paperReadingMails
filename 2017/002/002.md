# Headline

大家好：
 　　<b><span style="color:green">这是本年度第2篇Arxiv Weekly。</span> </b>
　　文章是关于如何提高检测准确度。其着眼点在于利用IoU-Net提升NMS选框的性能，并利用新的方法微调选出的bbox。 

# Source

### 研究机构

- 北京大学（Peking University）
- 清华大学（Tsinghua University）
- 旷视科技 （Face++）
- 头条人工智能实验室（Toutiao AI Lab）

### 文章链接
 - https://arxiv.org/pdf/1807.11590.pdf

# Introduction

&emsp;&emsp;现代CNN目标检测器中，一般都存在 <span style="color:brown">Non-maximum suppression   (NMS)</span> 选框和bbox回归的过程。然而这里面的逻辑是有一定的问题的。 <span style="color:red">NMS操作的置信度本质上来源于classification的label，而不是localization，这不可避免地导致了一些localization性能的降退</span>，即使后续有进一步的回归。

&emsp;&emsp;本文提出了IoU-Net结构，能够预测每个候选框和对应的ground truth框之间的IoU。由于在选框的时候真正考虑了localization信息，IoU-Net能够优化NMS过程，给出更精准的预选框。另外，本文也提出了bbox refinement算法，来进一步提高最终框的精度。

&emsp;&emsp;在MSCOCO上的实验表明本文提出的方法能在经典detection pipeline上取得涨点，并且具有良好的兼容性和可迁移性。

# Keys

### 1.问题描述

-  <span style="color:red">misalignment between classification and localization accuracy. </span> <span style="color:grey">[也即NMS会舍弃更好的框，挑选烂框来回归]</span>

<img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2017/002/002_01.png?raw=true" width = "100%" />

-  <span style="color:red">the absence of localization confidence makes bbox regression less interpretable.</span> <span style="color:grey"> [也即随着迭代的进行，bbox的回归结果反而恶化]</span>

<img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2017/002/002_02.png?raw=true" width = "100%" />

### 2.解决方案part1：IoU-guided NMS

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2017/002/002_03.png?raw=true" width = "80%" /></center>

&emsp;&emsp;此为文中提出的新NMS算法，其核心为利用bbox对应区域和真值的IoU作为挑选maximum bbox的依据，而不是像传统的NMS一样直接用classification score来作为依据，这就弥合了misalignment between classification and localization accuracy。

&emsp;&emsp;另外值得一提的是，IoU-guided NMS算法中，在抑制那些和最大框交集超过阈值的框的同时，会参考它们的分类信息。如果它们的分类置信度高于我们选出的最大框，则会更新最大框的分类。<span style="color:grey">[这个操作中，分离classification和localization的意味也很重，甚至有点localization指导优化classification的意思在里面。不过个人感觉这种情况并不常见]</span>

&emsp;&emsp;剩下的一个关键问题是，给出一个bbox，我们怎么知道它和真值的bbox的IoU是多少……

&emsp;&emsp;文章中采用了如下的IoU-Net网络来解决这个问题。

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2017/002/002_04.png?raw=true" width = "100%" /></center>

&emsp;&emsp;<span style="color:blue">网络的训练数据是通过ground truth + augmentation & randomization生成的。</span>

### 3.解决方案part2：optimization based bounding box refinement

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2017/002/002_05.png?raw=true" width = "80%" /></center>

&emsp;&emsp;核心的思路在于利用IoU Net对bbox的IoU预测能力，指导后续的bbox微调。微调的时候用最简单的梯度上升优化方法，并设定两个阈值，一个用来判定收敛；一个用来判定是否已经进入localization degeneration的阶段并予以遏制。

&emsp;&emsp;p.s. 我们可以看到，不同的refinement方法，都是在寻找一种方式解决如下的最优化问题：

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2017/002/002_06.png?raw=true" width = "100%" /></center>

&emsp;&emsp;其中det是检测网络输出的bbox；gt是真值bbox；c是网络微调器transfomer的参数；crit是loss函数形式<span style="color:grey">[一般选取smooth-L1 distance]</span>

### 4.关于precise ROI pooling

&emsp;&emsp;为了能够实现3中的算法，我们需要给出一个可导的RoI Pooling算法。RoI Align算法已经比较好地解决了RoI中misalignment的问题，因此其基本想法是应该沿用的。所需要解决的是导数求解的问题。

&emsp;&emsp;因此<span style="color:blue">本文提出了精准RoI Pooling (PrRoI Pooling)算法，其实质就是把feature map上的点利用双线性插值 (bilinear interpolation)算法转化为连续的函数</span>，如下公式所示：

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2017/002/002_07.png?raw=true" width = "100%" /></center>

&emsp;&emsp;有了连续的feature map值，就能够把bbox以浮点数的形式直接套在feature map对应的位置上，并且进行pooling操作了。<span style="color:grey">[不过由于连续性的操作，我理解这里的PrRoI Pooling更加像一种average pooling的变体]</span>

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2017/002/002_13.png?raw=true" width = "100%" /></center>
