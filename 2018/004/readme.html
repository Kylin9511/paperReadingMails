<!DOCTYPE html>
  <html>
    <head>
      <title>readme</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////home/luzhilin/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.3.5/node_modules/@shd101wyy/mume/dependencies/katex/katex.min.css">
      
      
      
      
      
      
      
      
      
      

      <style> 
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
 
      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview   ">
      <h1 class="mume-header" id="headline">Headline</h1>

<p>大家好：</p>
<p><b><span style="color:green">这是2018年度第4篇Arxiv Weekly。</span> </b></p>
<p>本文是 <strong>模型压缩、NAS</strong> 方向的文章。</p>
<h1 class="mume-header" id="highlight">Highlight</h1>

<blockquote>
<p><strong>Song Han组新工作，利用网络自动搜索技术进行网络压缩，并取得超过手动压缩的性能。</strong></p>
</blockquote>
<h1 class="mume-header" id="information">Information</h1>

<h3 class="mume-header" id="title">Title</h3>

<p><em>AMC: AutoML for Model Compression and Acceleration on Mobile Devices</em></p>
<h3 class="mume-header" id="link">Link</h3>

<p><a href="https://arxiv.org/pdf/1802.03494.pdf">https://arxiv.org/pdf/1802.03494.pdf</a></p>
<h3 class="mume-header" id="source">Source</h3>

<ul>
<li>麻省理工大学（Massachusetts Institute of Technology）</li>
<li>西安交大（Xian Jiaotong University）</li>
<li>谷歌（Google）</li>
</ul>
<h1 class="mume-header" id="introduction">Introduction</h1>

<p>模型压缩已经成为神经网络移动化技术的核心之一。在有限的计算资源和能量条件下如何实现模型的部署，是神经网络落地的关键问题。</p>
<p>CNN压缩技术的出现给这个问题提供了一个有力的解决方案。然而传统的模型压缩是纯手动的，基本是基于一些启发式的规则（heuristic rule-based compression）探索模型储存、效率和性能的最佳平衡。 手动的启发式平衡点，显然是次优化的，而且这样的压缩十分耗时，需要有经验的工程师和大量的时间和算力。</p>
<p>本文中提出了自动化模型压缩策略（<span style="color:brown">AutoML for Model Compression, AMC</span>）, 基于强化学习来进行模型压缩。实验结果表明，相比于启发式规则指导的模型压缩，AMC能够获得更高的压缩率的同时保留更多的性能。</p>
<p>以FLOPs为指标，用AMC指导VGG的4倍压缩相比于手动压缩涨点2.7%。在MobileNet上利用AMC进一步压缩网络，在安卓手机平台和Titan XP GPU上分别实现了ImageNet Inference中1.81<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.58333em;"></span><span class="strut bottom" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="base"><span class="mord">×</span></span></span></span> 和1.43<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.58333em;"></span><span class="strut bottom" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="base"><span class="mord">×</span></span></span></span>的加速，top1 acc仅仅降低了0.1%。</p>
<h1 class="mume-header" id="keys">Keys</h1>

<h3 class="mume-header" id="1-%E5%85%88%E9%AA%8Cpruning%E6%8A%80%E5%B7%A7">1. 先验pruning技巧</h3>

<p>一般来说，启发式的压缩会考虑如下的因素：</p>
<ul>
<li>尽量降低第一个layer的pruning rate，因为第一个layer往往参数量不大，而且其抽象的底层特征是否准确会影响后续的所有layer的性能。</li>
<li>尽量多在FC layer做压缩，因为FC layer一般非常臃肿，占据了极大的储存和计算资源，并且高层的特征重复度高。</li>
<li>尽量找准每个layer的敏感点，pruning rate不能超过这个阈值。</li>
</ul>
<p>但是显然，<span style="color:red">这三条原则从最优性上不能得证，从可操作性上需要大量的实验去调整各个layer的阈值，最糟糕的是只要模型改变所有的努力都需要重来一次，先验成果推广困难。</span></p>
<h3 class="mume-header" id="2-%E9%97%AE%E9%A2%98%E5%88%86%E7%B1%BB">2. 问题分类</h3>

<p>我们知道，传统的pruning研究分成两个大类：</p>
<ul>
<li><em>Fine-grained pruning</em> 旨在独立地考察和剪枝weight tensor中的每个elements。由于操作空间大，可以几乎无损地实现较大比例的压缩，但是需要配合<a href="https://arxiv.org/pdf/1602.01528.pdf">EIE</a>一类的针对性硬件结构来保证inference的效率。</li>
<li><em>Coarse-grained pruning</em> 粗粒度pruning操作针对weight tensor中的某一块操作，例如一行、一列、一个channel。由于结构整饬，虽然压缩比例较小，但是inference的效率不受什么影响，能够在通用硬件上实现较好的性能。</li>
</ul>
<p><span style="color:blue">本文中研究的是Coarse-grained pruning中channel层面的压缩，但是同样的方法可以用在其他类型的pruning当中。</span></p>
<h3 class="mume-header" id="3-amc%E7%9A%84pipeline">3. AMC的pipeline</h3>

<p>文章提出的AMC结构如下图所示：</p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/004/004_01.png?raw=true" width="55%"></center>
<p>可以看到整体上是标准的RL结构，而且能大体看出是<a href="http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_5_actor_critic_pdf.pdf">Actor-Critic</a>结构，具体的大家可以参考莫烦大佬的<a href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/6-1-actor-critic/">讲解</a>和<a href="https://github.com/princewen/tensorflow_practice/tree/master/Basic-Actor-Critic">代码</a>。实际上本文是使用了Actor-Critic结构的最新变体DDPG（Deep Deterministic Policy Gradient）结构，在后面会进一步描述。</p>
<h3 class="mume-header" id="4-%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4%E5%AE%9A%E4%B9%89">4. 状态空间定义</h3>

<p>对于每个layer，考虑优化如下的状态空间</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub><mo>=</mo><mrow><mo fence="true">(</mo><mi>t</mi><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo separator="true">,</mo><mi>k</mi><mo separator="true">,</mo><mi>F</mi><mi>L</mi><mi>O</mi><mi>P</mi><mi>s</mi><mo>[</mo><mi>t</mi><mo>]</mo><mo separator="true">,</mo><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi><mi>d</mi><mo separator="true">,</mo><mi>r</mi><mi>e</mi><mi>s</mi><mi>t</mi><mo separator="true">,</mo><msub><mi>a</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">s_t = \left( t,n,c,h,w,stride,k,FLOPs[t],reduced,rest,a_{t-1} \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathit">t</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit">n</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit">c</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit">h</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit">s</span><span class="mord mathit">t</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">i</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mord mathit">L</span><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">s</span><span class="mopen">[</span><span class="mord mathit">t</span><span class="mclose">]</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">e</span><span class="mord mathit">d</span><span class="mord mathit">u</span><span class="mord mathit">c</span><span class="mord mathit">e</span><span class="mord mathit">d</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">e</span><span class="mord mathit">s</span><span class="mord mathit">t</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathit">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.61508em;"></span><span class="strut bottom" style="height:0.61508em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">t</span></span></span></span>为layer的编号，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mi>L</mi><mi>O</mi><mi>P</mi><mi>s</mi><mo>[</mo><mi>t</mi><mo>]</mo></mrow><annotation encoding="application/x-tex">FLOPs[t]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mord mathit">L</span><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">s</span><span class="mopen">[</span><span class="mord mathit">t</span><span class="mclose">]</span></span></span></span>为layer的FLOPs值，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>a</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">a_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="base"><span class="mord"><span class="mord mathit">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"></span></span></span></span></span></span></span></span>为上一层的压缩率（此处定义为压缩至百分之多少，也即稀疏率）</p>
<p>而比较有趣的是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">reduced</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">e</span><span class="mord mathit">d</span><span class="mord mathit">u</span><span class="mord mathit">c</span><span class="mord mathit">e</span><span class="mord mathit">d</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">rest</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.61508em;"></span><span class="strut bottom" style="height:0.61508em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">e</span><span class="mord mathit">s</span><span class="mord mathit">t</span></span></span></span>，前者是指本层前的所有layer剪枝减掉的所有FLOPs；后者是指本层后的所有layer原始的所有FLOPs。这两个参数的存在是方便agent区分不同的layer，以便给出不同的剪枝策略。</p>
<h3 class="mume-header" id="5-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0agent%E4%BB%8B%E7%BB%8D%E4%B8%8E%E9%80%89%E6%8B%A9">5. 强化学习agent介绍与选择</h3>

<p>传统的NAS中，一般Action space是高度离散的，例如<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>{</mo><mn>6</mn><mn>4</mn><mo separator="true">,</mo><mn>1</mn><mn>2</mn><mn>8</mn><mo separator="true">,</mo><mn>2</mn><mn>5</mn><mn>6</mn><mo separator="true">,</mo><mn>5</mn><mn>1</mn><mn>2</mn><mo>}</mo></mrow><annotation encoding="application/x-tex">\{64,128,256,512\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mopen">{</span><span class="mord">6</span><span class="mord">4</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mord">2</span><span class="mord">8</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord">5</span><span class="mord">6</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span><span class="mclose">}</span></span></span></span>就足够覆盖一个优秀结构所需要用到的channels数量。额外增加一个65对搜索结构的优化没有太大帮助。</p>
<p>然而在网络压缩问题当中，网络结构对压缩率的敏感程度很高。可能0.19的压缩率网络就灾难性崩坏了，但是0.2的压缩率网络acc会基本不降。为了适应不用backbone的压缩需求，显然AMC当中的agent需要拥有连续的action space，输出一个具体的压缩率而不是从压缩率列表中选一个。这就指向了Policy Gradients结构而不是最早的DQN系列结构。</p>
<p>至于为什么选择Actor-Critic，莫烦有过<a href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/6-1-A-AC/">比较精彩的论述</a></p>
<blockquote>
<p>我们有了像 Q-learning这么伟大的算法, 为什么还要瞎折腾出一个 Actor-Critic? 原来 Actor-Critic 的 Actor 的前生是 Policy Gradients, 这能让它毫不费力地在连续动作中选取合适的动作, 而 Q-learning 做这件事会瘫痪. 那为什么不直接用 Policy Gradients 呢? 原来 Actor Critic 中的 Critic 的前生是 Q-learning 或者其他的 以值为基础的学习法 , 能进行单步更新, 而传统的 Policy Gradients 则是回合更新, 这降低了学习效率.</p>
</blockquote>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/004/004_02.png?raw=true" width="50%"></center>
<p>Actor-Critic算法的大概过程如下：Actor选择动作，Critic来告诉Actor它选择的动作是否合适。在这一过程中，Actor不断迭代，得到每一个状态下选择每一动作的合理概率，Critic也不断迭代，不断完善每个状态下选择每一个动作的奖惩值。</p>
<p>本文实际选用的DDPG和Actor-Critic原理上是一码事，DDPG是为了修正Actor-Critic存在如下的问题衍生出来的工作。</p>
<blockquote>
<p>Actor-Critic 涉及到了两个神经网络, 而且每次都是在连续状态中更新参数, 每次参数更新前后都存在相关性, 导致神经网络只能片面的看待问题, 甚至导致神经网络学不到东西</p>
</blockquote>
<p>因此DDPG选择引入在电动游戏Atari上大获成功的DQN系列工作经验，采用经验池和双网络结构来优化原本的Actor-Critic架构。关于DDPG的详细原理和思路，莫烦也有<a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-09-DDPG/">精彩的讲解</a>。</p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/004/004_03.png?raw=true" width="55%"></center>
<p>其中：</p>
<ul>
<li>经验池（experience replay）是为了解决DL目标分布固定；RL的分布一直变化的问题， <span style="color:blue">能够打破参数更新的相关性</span>。</li>
<li><span style="color:blue">而双网络结构则是维持了整体网络预测过程的稳定性，解决了非线性网络表示值函数时出现不稳定等问题。</span>具体来说，我们只需要训练动作估计网络和状态估计网络的参数，而动作现实网络和状态现实网络的参数是由前面两个网络每隔一定的时间复制过去的</li>
</ul>
<h3 class="mume-header" id="6-%E4%B8%A4%E7%B1%BB%E7%9B%AE%E6%A0%87%E7%9A%84search-protocal%E8%AE%BE%E8%AE%A1">6. 两类目标的search protocal设计</h3>

<h5 class="mume-header" id="resource-constrained-compression">Resource-Constrained Compression</h5>

<p>实际上，本文当中没有针对资源限制修改网络中的loss，使用的是完全通用的loss函数</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mrow><mi>e</mi><mi>r</mi><mi>r</mi></mrow></msub><mo>=</mo><mo>−</mo><mi>E</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">R_{err} = -Error</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">e</span><span class="mord mathit mtight" style="margin-right:0.02778em;">r</span><span class="mord mathit mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mord">−</span><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span></span></span></span></span></p>
<p>对于不同的资源限制，能够得到不同的临界压缩率。本文实现资源限制网络搜索的方式是限制action space。也即当发现后续的所有layer即使都进行毁灭性剪枝都无法满足总体的资源限制的时候，开始对action进行控制。</p>
<p>这样的方法有一个显著的好处，就是不同种类的资源限制都能够套用这个框架，例如FLOPs、inference时间、储存空间等等。</p>
<h5 class="mume-header" id="accuracy-guaranteed-compression">Accuracy-Guaranteed Compression</h5>

<p>对于在保证acc不降的情况下尽可能压缩网络的需求，本文通过修改loss函数的方式实现。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mrow><mi>F</mi><mi>L</mi><mi>O</mi><mi>P</mi><mi>s</mi></mrow></msub><mo>=</mo><mo>−</mo><mi>E</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi><mo>⋅</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo>(</mo><mi>F</mi><mi>L</mi><mi>O</mi><mi>P</mi><mi>s</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">R_{FLOPs} = -Error \cdot log(FLOPs)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right:0.13889em;">F</span><span class="mord mathit mtight">L</span><span class="mord mathit mtight" style="margin-right:0.02778em;">O</span><span class="mord mathit mtight" style="margin-right:0.13889em;">P</span><span class="mord mathit mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mord">−</span><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="mord mathit">L</span><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">s</span><span class="mclose">)</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mrow><mi>P</mi><mi>a</mi><mi>r</mi><mi>a</mi><mi>m</mi></mrow></msub><mo>=</mo><mo>−</mo><mi>E</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi><mo>⋅</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo>(</mo><mi mathvariant="normal">#</mi><mi>P</mi><mi>a</mi><mi>r</mi><mi>a</mi><mi>m</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">R_{Param} = -Error \cdot log(\#Param)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right:0.13889em;">P</span><span class="mord mathit mtight">a</span><span class="mord mathit mtight" style="margin-right:0.02778em;">r</span><span class="mord mathit mtight">a</span><span class="mord mathit mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mord">−</span><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">#</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">a</span><span class="mord mathit">m</span><span class="mclose">)</span></span></span></span></span></p>
<p>显然，这样的loss对Error是非常敏感的，训练的结果会优先保障acc性能。而FLOPs或者model size也会参与到reward的惩罚中，因此搜索的结果会倾向于高acc条件下尽可能进行模型压缩。</p>
<h3 class="mume-header" id="7-%E7%AE%97%E6%B3%95%E4%BC%AA%E4%BB%A3%E7%A0%81">7. 算法伪代码</h3>

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/004/004_04.png?raw=true" width="50%"></center>
<h1 class="mume-header" id="results">Results</h1>

<center> 
<img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/004/004_05.png?raw=true" width="50%">
<p>AMC和之前的hand-craft模型压缩方法性能对比</p>
</center>
<center> 
<img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/004/004_07.png?raw=true" width="50%">
<p>在ResNet50上精度不降条件下，hand-craft（压缩3.4倍）和AMC（压缩5倍）对比</p>
</center>
<center> 
<img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/004/004_06.png?raw=true" width="50%">
<p>利用RL算法搜索出来的各个layer压缩率鉴赏</p>
</center>
<center> 
<img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/004/004_08.png?raw=true" width="50%">
<p>在ImageNet上压缩VGG和MobileNet也获得成功</p>
</center>
<center> 
<img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/004/004_09.png?raw=true" width="50%">
<p>对检测领域的小测试：在PascalVOC2007上压缩VGG16，性能基本得到保证</p>
</center>
<h1 class="mume-header" id="insights">Insights</h1>

<p>最近NAS的大潮汹涌，其中DeepMind一马当先，前序Keys-5中降到的agent基本都来源于DeepMind。本文可以算是RL、NAS在模型压缩子领域的自然延伸。</p>
<p>在创造性方面，其实没有太多值得称道的地方。不过状态空间的设置和Resource Restricted设置的方式还是值得参考的。</p>
<p>最近出于不明原因，出现了很多搞这个的工作。</p>
<p>谷歌的自动模型压缩框架Tensorflow-Lite：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650749042&amp;idx=3&amp;sn=9394b2a2ffd56c53d23eb15c8162d0f3&amp;chksm=871afc0cb06d751ab0863d1709f8a9ca048a0335cafa7482444730af6b0a528c018b96b3c45f&amp;mpshare=1&amp;scene=1&amp;srcid=0924DNx2ZhGLOesdJs4njAzI&amp;pass_ticket=g3mcLrDR19mg%2B9gQi9wO6F66fPNKwEjo8XkhrB%2BiDr%2FdXueZROzsI3fnKSZOhKzc#rd">介绍推送</a></li>
<li><a href="https://www.tensorflow.org/mobile/tflite/">官方介绍</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/tutorials/post_training_quant.ipynb">官方教程</a></li>
</ul>
<p>腾讯的自动模型压缩框架PocketFlow：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650748704&amp;idx=3&amp;sn=a0273534c0490ae62537482c2e13fbdc&amp;chksm=871af35eb06d7a483be83d6d83332f9a3f5e1ee89458e968072b711ac068340cecc8d3a0fff8&amp;scene=0&amp;pass_ticket=g3mcLrDR19mg%2B9gQi9wO6F66fPNKwEjo8XkhrB%2BiDr%2FdXueZROzsI3fnKSZOhKzc#rd">介绍推送</a></li>
<li>代码：仍未但是据说即将开源</li>
</ul>

      </div>
      
      
    </body>
    
    
    
    
    
    
    
  </html>