<!DOCTYPE html>
  <html>
    <head>
      <title>readme</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////home/luzhilin/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.3.5/node_modules/@shd101wyy/mume/dependencies/katex/katex.min.css">
      
      
      
      
      
      
      
      
      
      

      <style> 
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
 
      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview   ">
      <h1 class="mume-header" id="headline">Headline</h1>

<p>大家好：</p>
<p><b><span style="color:green">这是2018年度第1篇Arxiv Weekly。</span> </b></p>
<p>本文是 <strong>人脸</strong> 方向的文章。</p>
<h1 class="mume-header" id="highlight">Highlight</h1>

<blockquote>
<p><strong>本文通过多轮廓估计层（shape prediction layer, SPL）更好地在遮挡、多相外观等复杂数据条件下解决了face alignment问题。</strong></p>
</blockquote>
<h1 class="mume-header" id="information">Information</h1>

<h3 class="mume-header" id="title">Title</h3>

<p><em>Deep Multi-Center Learning for Face Alignment</em></p>
<h3 class="mume-header" id="link">Link</h3>

<p><a href="https://arxiv.org/pdf/1808.01558.pdf">https://arxiv.org/pdf/1808.01558.pdf</a></p>
<h3 class="mume-header" id="codes">Codes</h3>

<p><a href="https://github.com/ZhiwenShao/MCNet-Extension">https://github.com/ZhiwenShao/MCNet-Extension</a></p>
<h3 class="mume-header" id="source">Source</h3>

<ul>
<li>上海交通大学（Shanghai Jiao Tong University）</li>
<li>华东师范大学（East China Normal University）</li>
</ul>
<h1 class="mume-header" id="introduction">Introduction</h1>

<p>人脸特征点（Facial Landmarks）之间有较强的相关性，显然一个特征点的位置可以从其相邻特征点的位置进行后验推断。然而传统的DL算法一般只使用一个FC层（也即所谓的轮廓估计层<span style="color:brown">shape prediction layer, SPL</span>）进行人脸特征点估计。</p>
<p>本文提出了face alignment的最新架构：包含多个轮廓估计层的多中心点架构（<span style="color:brown">Multi-Center Learning with multiple shape prediction layers， MCL</span>）。具体来说，<span style="color:blue">每个SPL主要负责检测一簇语义相关的特征点，其中难以检测的特征点优先检测，而后对每一簇特征点分别针对性优化</span>。</p>
<p>另外，为了降低模型的复杂度，<span style="color:blue">本文利用模型组合的思路把所有的sub-SPL整合成一个大SPL</span>。</p>
<p>实验表明本文的方法能够更好地解决面部遮挡、同一个人不同的appearance等复杂的face alignment问题<span style="color:grey">[复杂例子和alignment结果如下图所示，下图为本篇的前序工作MCNet文章中的图例]</span>，并且维持实时性。</p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_01.png?raw=true" width="55%"></center>
<h1 class="mume-header" id="keys">Keys</h1>

<p>本文有两个需要解析的关键点：网络结构和训练方式。</p>
<h3 class="mume-header" id="1%E6%9C%AC%E6%96%87%E9%87%87%E7%94%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%A6%82%E4%B8%8B">1.本文采用的网络结构如下：</h3>

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_02.png?raw=true" width="55%"></center>
<p>可以看到，预处理之后的图片输入网络后，通过三组(Conv, Conv, MaxPooling)模块后，输入后续的三层卷积中，再通过global pooling得到最终的特征。这个特征被同时送入m个SPL，最终通过assemble获得n个final landmarks。<span style="color:grey">[其中每个Conv后都附加了BN和ReLU]<br>
</span></p>
<h3 class="mume-header" id="2%E6%9C%AC%E6%96%87%E7%9A%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E6%9C%89%E5%A6%82%E4%B8%8B%E8%A6%81%E7%82%B9">2.本文的训练过程有如下要点：</h3>

<h4 class="mume-header" id="21-%E8%AE%AD%E7%BB%83%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B">2.1 训练总体流程</h4>

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_03.png?raw=true" width="55%"></center>
<p>分为pre-train---weighting finetune---multi-center finetune---model assembling几个阶段，下面分别解析。</p>
<h4 class="mume-header" id="22-loss%E5%87%BD%E6%95%B0%E8%AE%BE%E8%AE%A1">2.2 Loss函数设计</h4>

<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_04.png?raw=true" width="55%"></center>
<p>是一个含有weight，也即<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"></span></span></span></span></span></span></span></span>的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mspace width="0.277778em"></mspace><msub><mtext>L</mtext><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\;\text{L}_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base"><span class="mspace thickspace"></span><span class="mord"><span class="mord text"><span class="mord">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span> loss。</p>
<h4 class="mume-header" id="23-weighting-finetune%E8%AE%BE%E8%AE%A1">2.3 weighting finetune设计</h4>

<p>在训练的Step2中，前面六层卷积被固定，后三层卷积先进行finetune；而后在Step3中，整个网络进行最终的finetune。之所以称为weighting finetune，是因为在微调的时候，loss越大的路径上调整力度越大，由如下的weighting控制。这样一来，能够将有限的力量集中在challenging case上。</p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_05.png?raw=true" width="55%"></center>
<h4 class="mume-header" id="24-multi-center-finetune%E8%AE%BE%E8%AE%A1">2.4 multi-center finetune设计</h4>

<p>进行到这一步后，前面的特征抽象网络全部训练完毕。开始训练SPL层。所谓的multi-center，是指把最终的landmarks分配到不同的几个簇，每个簇是一块面部特征对应的特征点集合，例如眼睛、鼻子、嘴、脸颊轮廓等<span style="color:grey">[如下图所示]</span>。然后每个SPL层针以某个簇为优化的中心，着力准确地刻画自己簇中所有landmark。</p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_06.png?raw=true" width="55%"></center>
<p>而进行multi-center focus的方案，也是设计启发式的weighting参数，最终公式如下。这个公式能够保障SPL对本簇内landmark的优化力度是簇外landmark的alpha倍。<span style="color:grey">[alpha &gt;&gt; 1]</span></p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_07.png?raw=true" width="55%"></center>
<h4 class="mume-header" id="25-model-assembling%E6%96%B9%E6%A1%88">2.5 model assembling方案</h4>

<p>最终你会得到m个SPL，它们有不彼此重叠的center/簇。因此进行合并的最自然方案，就是使得最终生成的所有landmark都来自自己簇对应的SPL。而因为SPL之间簇没有重叠，这个融合过程可以通过直接融合weighting进行。<span style="color:grey">[这里有些绕，可能需要一定时间理解]</span></p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_08.png?raw=true" width="55%"></center>
<h4 class="mume-header" id="26-weight-matrix%E4%B8%8E%E5%8F%8D%E4%BC%A0%E7%9A%84%E7%BB%93%E5%90%88%E6%96%B9%E5%BC%8F">2.6 weight matrix与反传的结合方式</h4>

<p>注意这个部分原文的表述比较有误导性。代表weighting的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02691em;">w</span></span></span></span>和代表FC layer的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>W</mtext></mrow><annotation encoding="application/x-tex">\textbf{W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68611em;"></span><span class="strut bottom" style="height:0.68611em;vertical-align:0em;"></span><span class="base"><span class="mord text"><span class="mord textbf">W</span></span></span></span></span>是完全没关系的，weighting会自然融合在反传里，起到的作用就是提高被focus的landmark的lr。</p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_09.png?raw=true" width="55%"></center>
<h1 class="mume-header" id="results">Results</h1>

<p>下图给出了本文算法和常见同类算法的Mean Error对比。</p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_10.png?raw=true" width="55%"></center>
<p>下图给出了本文算法和前序工作MCNet的Mean Error对比：</p>
<center><img src="https://github.com/luzhilin19951120/paperReadingMails/blob/master/2018/001/001_11.png?raw=true" width="55%"></center>
<h1 class="mume-header" id="insights">Insights</h1>

<p>文章中设计的结构，在作者分析中有三个主要的好处：</p>
<ol>
<li>和主流CNN网络相比，本文网络结构显然轻量级很多，因此无论是training还是inference都会更加高效。</li>
<li>过深的网络结构会削弱spatial information的信息，抽象出来的更多是semantic information，因此本文的网络更加适用于facial landmark这样对spatial information要求很高的任务。</li>
<li>overfitting问题上，本文网络有天然的优势。</li>
</ol>
<p>除了从这些points中收到启发，本身文中设计的weighting机制也是比较精巧和值得分析的。</p>

      </div>
      
      
    </body>
    
    
    
    
    
    
    
  </html>